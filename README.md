# AI-Powered Visual Search System

[![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-blue?logo=docker&logoColor=white)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io/)
[![Qdrant](https://img.shields.io/badge/Qdrant-AC2845?logo=qdrant&logoColor=white)](https://qdrant.tech/)

An enterprise-grade visual search system that allows users to search through a vast image collection using natural language queries. This project leverages state-of-the-art AI models to provide not only semantically relevant images but also AI-generated explanations for *why* each result is a match.

---

## Features

* **Semantic Search**: Go beyond keywords. Search for images based on concepts, objects, actions, and scenes (e.g., "a happy dog playing in a park").
* **AI-Generated Explanations**: Each search result is accompanied by a concise explanation generated by GPT-4o-mini, building user trust and providing valuable insights.
* **High Performance**: Built with FastAPI and Qdrant for low-latency search, even with tens of thousands of images.
* **Scalable Architecture**: A containerized, microservices-based architecture using Docker Compose allows for easy scaling of individual components.
* **Modern Web Interface**: An intuitive and responsive UI built with Streamlit for a seamless user experience.

---

## System Architecture

The system is designed with a clear separation of concerns, comprising two main workflows: an **Offline Indexing Pipeline** and a **Real-time Search Pipeline**.


1.  **Indexing Pipeline (Offline)**: An administrator runs a script that processes all images in a dataset. The **CLIP model** converts each image into a vector embedding, which is then stored and indexed in the **Qdrant Vector Database**.
2.  **Search Pipeline (Real-time)**: A user enters a text query into the **Streamlit Frontend**. The **FastAPI Backend** uses the **CLIP model** to convert this text into a query vector, searches Qdrant for similar image vectors, and then uses **GPT-4o-mini** to generate an explanation for each match before returning the results to the user.

---

## Tech Stack

* **Backend**: FastAPI, Uvicorn
* **Frontend**: Streamlit
* **Vector Database**: Qdrant
* **AI Models**:
    * Image/Text Embedding: `openai/clip-vit-large-patch14`
    * Explanation Generation: `gpt-4o-mini`
* **Containerization**: Docker, Docker Compose
* **Core Python Libraries**: PyTorch, Transformers, Pillow, `python-dotenv`

---

## Getting Started

Follow these steps to get the application running locally.

### Prerequisites

* **Docker** and **Docker Compose**
* **Git**
* An **OpenAI API Key**

### Clone the Repository

```bash
git clone <your-repository-url>
cd visual-search-system
```

## Project Structure

visual-search-system/
├── docker-compose.yml         # Orchestrates all services
├── .env                       # Environment variable template
├── requirements.txt           # Python dependencies for the API
├── requirements_frontend.txt  # Python dependencies for Streamlit
│
├── api/                       # FastAPI Backend Application
│   ├── Dockerfile
│   ├── main.py
│   ├── core/
│   ├── services/
│   └── utils/
│
├── frontend/                  # Streamlit Web Interface
│   ├── Dockerfile
│   └── app.py
│
├── scripts/                   # Utility and one-off scripts
│   ├── download_images.py
│   └── generate_embeddings.py
│
└── data/                      # Local data
    └── images/                # image collection
    └── photos_url.csv         